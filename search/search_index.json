{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Compilers Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.1.2 (29 March 2021) \u251c Download [PDF] version Abstract\u2014 O ur IUST-Compiler Course is now more practical than ever. This repository contains several code snippets that I developed to teach the ANTLR compiler generator at Iran University of Science and Technology (UST). Grammars have been written in ANTRL v4 format. For each grammar, the source code of Lexer and Parser is available in Python 3.x. The repository is assumed to be updated regularly. It would be appreciated if you use this repository by forking it. For any question please contact me m-zakeri[at]live.com . Introduction The course is intended to teach the students the basic techniques that underlie the practice of Compiler Construction. The course will introduce the theory and tools that can be standardly employed to perform syntax-directed translation of a high-level programming language into executable code. These techniques can also be employed in broader areas of application, whenever we need a syntax-directed analysis of symbolic expressions and languages and their translation into a lower-level description. They have multiple uses for man-machine interaction, including verification and program analysis. Objectives To learn the overall compiler architecture, To learn various parsing methods and techniques, To learn low-level code generation and optimization, To learn an intellectual paradigm in system programming and testing. Motivations Compiler construction is a microcosm of computer science! You dive into the heart of the system when you are building a compiler. Examples The following outputs could be generated by code snippets in this repository. Three addresses codes Figure 1 shows how a single pass compiler can generate three address code for assignment statements with minimum numbers of temporary variable, started with T : Figure 1: Examples of three addresses codes generated by ANTLR for AssignmentStatement grammar. Abstract Syntax Tree Abstract syntax trees (ASTs) are a useful abstraction when dealing with programming languages as an object for analysis or manipulation (e.g. compilation). Figure 2 demonstrates how a single pass compiler can generate abstract syntax three (AST) for assignment statements. Figure 2: Examples of abstract syntax tree (AST) generated by ANTLR for AssignmentStatement grammar. The above tree corresponds to the following expression: a1 := (2 + 12 * 3) / (6 - 19) Structure The following describes the structure of the repository: grammars gram1 : ANTLR hello world grammar. Expr1 : Simple grammar for handling mathematical expressions without any attribute and action. Expr2 : Simple attributed grammar for handling mathematical expressions with code() attribute. Expr3 : Currently, it is the same Expr2 grammar. AssignmentStatement1.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . AssignmentStatement2.g4 : It is the same AssignmentStatement1.g4 grammar plus attributes for code and type of rules. AssignmentStatement3.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. AssignmentStatement4.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. It has been implemented to generate intermediate representation (three addresses codes) with minimum number of \"temp\" variables. CPP14_v2 : ANTLR grammar for C++14 forked from the official ANTRL website. Some bugs have been fixed and also the rule identifiers have been added to the grammar rules. EMail.g4 : Lexical grammar to validate email addresses. EMail2.g4 : Lexical grammar to validate email addresses, fixing bugs in EMail.g4 language_apps The language_apps package currently contains Lexer and Parser codes for each grammar in directory grammars , with a main driver script to demonstrate the type checking and intermediate code generation based on semantic rules and semantic routines . terminal_batch_scripts The termina_batch_script directory contains several batch script to run ANTLR in terminal (Windows) to generate target code in JAVA language. The code snippets in this directory belong to my first experiences with ANTLR. Read more IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C#","title":"Home"},{"location":"#compilers","text":"Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.1.2 (29 March 2021) \u251c Download [PDF] version Abstract\u2014 O ur IUST-Compiler Course is now more practical than ever. This repository contains several code snippets that I developed to teach the ANTLR compiler generator at Iran University of Science and Technology (UST). Grammars have been written in ANTRL v4 format. For each grammar, the source code of Lexer and Parser is available in Python 3.x. The repository is assumed to be updated regularly. It would be appreciated if you use this repository by forking it. For any question please contact me m-zakeri[at]live.com .","title":"Compilers"},{"location":"#introduction","text":"The course is intended to teach the students the basic techniques that underlie the practice of Compiler Construction. The course will introduce the theory and tools that can be standardly employed to perform syntax-directed translation of a high-level programming language into executable code. These techniques can also be employed in broader areas of application, whenever we need a syntax-directed analysis of symbolic expressions and languages and their translation into a lower-level description. They have multiple uses for man-machine interaction, including verification and program analysis.","title":"Introduction"},{"location":"#objectives","text":"To learn the overall compiler architecture, To learn various parsing methods and techniques, To learn low-level code generation and optimization, To learn an intellectual paradigm in system programming and testing.","title":"Objectives"},{"location":"#motivations","text":"Compiler construction is a microcosm of computer science! You dive into the heart of the system when you are building a compiler.","title":"Motivations"},{"location":"#examples","text":"The following outputs could be generated by code snippets in this repository.","title":"Examples"},{"location":"#three-addresses-codes","text":"Figure 1 shows how a single pass compiler can generate three address code for assignment statements with minimum numbers of temporary variable, started with T : Figure 1: Examples of three addresses codes generated by ANTLR for AssignmentStatement grammar.","title":"Three addresses codes"},{"location":"#abstract-syntax-tree","text":"Abstract syntax trees (ASTs) are a useful abstraction when dealing with programming languages as an object for analysis or manipulation (e.g. compilation). Figure 2 demonstrates how a single pass compiler can generate abstract syntax three (AST) for assignment statements. Figure 2: Examples of abstract syntax tree (AST) generated by ANTLR for AssignmentStatement grammar. The above tree corresponds to the following expression: a1 := (2 + 12 * 3) / (6 - 19)","title":"Abstract Syntax Tree"},{"location":"#structure","text":"The following describes the structure of the repository:","title":"Structure"},{"location":"#grammars","text":"gram1 : ANTLR hello world grammar. Expr1 : Simple grammar for handling mathematical expressions without any attribute and action. Expr2 : Simple attributed grammar for handling mathematical expressions with code() attribute. Expr3 : Currently, it is the same Expr2 grammar. AssignmentStatement1.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . AssignmentStatement2.g4 : It is the same AssignmentStatement1.g4 grammar plus attributes for code and type of rules. AssignmentStatement3.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. AssignmentStatement4.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. It has been implemented to generate intermediate representation (three addresses codes) with minimum number of \"temp\" variables. CPP14_v2 : ANTLR grammar for C++14 forked from the official ANTRL website. Some bugs have been fixed and also the rule identifiers have been added to the grammar rules. EMail.g4 : Lexical grammar to validate email addresses. EMail2.g4 : Lexical grammar to validate email addresses, fixing bugs in EMail.g4","title":"grammars"},{"location":"#language_apps","text":"The language_apps package currently contains Lexer and Parser codes for each grammar in directory grammars , with a main driver script to demonstrate the type checking and intermediate code generation based on semantic rules and semantic routines .","title":"language_apps"},{"location":"#terminal_batch_scripts","text":"The termina_batch_script directory contains several batch script to run ANTLR in terminal (Windows) to generate target code in JAVA language. The code snippets in this directory belong to my first experiences with ANTLR.","title":"terminal_batch_scripts"},{"location":"#read-more","text":"IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C#","title":"Read more"},{"location":"antlr_tutorials/antlr_advanced/","text":"ANTLR advanced tutorials By: Morteza Zakeri Last update: April 30, 2022 Compiler background We first define some terms used in compiler literature when analyzing the program based on the ANTLR vocabulary. Compiler pass. Each time that the walk method of ParseTreeWalker class is called, it visits all nodes of the parse tree. In compiler literature, we called this process a pass. The ANTLR pass can be annotated with listener classes to perform specific analysis or transformation. An analysis pass refers to the pass in which some information is obtained from the source code, but the source code is not changed, or no new code is generated. A transformation pass refers to the pass in which the program source code is modified or new codes are generated. As we discussed in the next sections, refactoring automation consists of both the analysis and transformation passes. Single v.s. multiple pass. Often to perform specific analyses or transformations, the program should be visited multiple times. Indeed, such tasks required multiple passes. For instance, if a class attribute is defined after it is used in a method, which is possible in Java programming language, to find the definition of the field and then modify its usage, we should visit the program twice. The reason is that the program tokens are read from left to right, and then when traversing the parse tree, the node only is visited once in the order they appear in the program text. For a given task, if we visit a node and require the information obtained from the next nodes, we cannot complete the task in one pass. In such a case, a pass is required to obtain the necessary information from the next nodes, and another pass is required to use this information for the current node. Most refactoring operations we described in this chapter require multiple passes to complete the refactoring process. For each pass, we develop a separate listener class and pass it to ParseTreeWalker class. Summary An analysis that is performed by traversing the program once is called a single pass-analysis. An analysis that is performed by traversing the program source code twice or more is called multiple analysis passes. Todo: To be completed ...","title":"Advanced"},{"location":"antlr_tutorials/antlr_advanced/#antlr-advanced-tutorials","text":"By: Morteza Zakeri Last update: April 30, 2022","title":"ANTLR advanced tutorials"},{"location":"antlr_tutorials/antlr_advanced/#compiler-background","text":"We first define some terms used in compiler literature when analyzing the program based on the ANTLR vocabulary. Compiler pass. Each time that the walk method of ParseTreeWalker class is called, it visits all nodes of the parse tree. In compiler literature, we called this process a pass. The ANTLR pass can be annotated with listener classes to perform specific analysis or transformation. An analysis pass refers to the pass in which some information is obtained from the source code, but the source code is not changed, or no new code is generated. A transformation pass refers to the pass in which the program source code is modified or new codes are generated. As we discussed in the next sections, refactoring automation consists of both the analysis and transformation passes. Single v.s. multiple pass. Often to perform specific analyses or transformations, the program should be visited multiple times. Indeed, such tasks required multiple passes. For instance, if a class attribute is defined after it is used in a method, which is possible in Java programming language, to find the definition of the field and then modify its usage, we should visit the program twice. The reason is that the program tokens are read from left to right, and then when traversing the parse tree, the node only is visited once in the order they appear in the program text. For a given task, if we visit a node and require the information obtained from the next nodes, we cannot complete the task in one pass. In such a case, a pass is required to obtain the necessary information from the next nodes, and another pass is required to use this information for the current node. Most refactoring operations we described in this chapter require multiple passes to complete the refactoring process. For each pass, we develop a separate listener class and pass it to ParseTreeWalker class.","title":"Compiler background"},{"location":"antlr_tutorials/antlr_advanced/#summary","text":"An analysis that is performed by traversing the program once is called a single pass-analysis. An analysis that is performed by traversing the program source code twice or more is called multiple analysis passes. Todo: To be completed ...","title":"Summary"},{"location":"antlr_tutorials/antlr_basics/","text":"ANTLR basic tutorials By: Morteza Zakeri Last update: April 30, 2022 Introduction The ANTLR tool generates a top-down parser from the grammar rules defined with the ANTLR meta-grammar (Parr and Fisher 2011). The initial version of ANTLR generated the target parser source code in Java. In the current version (version 4), the parser source code can be generated in a wide range of programming languages listed on the ANTLR official website (Parr 2022a). For simplicity, we generate the parser in Python 3, which provides us to run the tool on every platform having Python 3 installed on it. Another reason to use Python is that we can integrate the developed program easily with other libraries available in Python, such as machine learning and optimization libraries. Finally, I found that there is no comprehensive tutorial on using ANTLR with the Python backend. To use ANTLR in other programming languages, specifically Java and C#, refer to the ANTLR slides I created before this tutorial. The ANTLR tool is a small \u201c.jar\u201d file that must be run from the command line to generate the parser codes. The ANTLR tool jar file can be downloaded from here . Generating parser As mentioned, to generate a parser for a programming language, the grammar specification described with ANTLR meta-grammar is required. ANTLR grammar files are named with the \u201c.g4\u201d suffix. We obtain the grammar of Java 8 to build our parser for the Java programming language. The grammar can be downloaded from ANTLR 4 grammar repository on GitHub: https://github.com/antlr/grammars-v4 . Once the ANTLR tool and required grammar files are prepared, we can generate the parser for that with the following command: > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -o . JavaLexer.g4 > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -visitor -listener -o . JavaLabeledParser.g4 The first command generates the lexer from the JavaLexer.g4 description file and the second command generates the parser from the JavaLabeledParser.g4 description file. It is worth noting that the lexer and parser can be written in one file. In such a case, a single command generates all required codes in one step. The grammar files used in the above command are also available in grammars directory of the CodART repository. You may see that I have made some modifications to the Parser rules. In the above commands, the antlr-4.9.3-complete.jar is the ANTLR tool that requires Java to be executed. -Dlanguage denotes the destination language that the ANTLR parser (and lexer) source code is generated in which. In our case, we set it to Python3. After executing the ANTLR parser generation commands, eight files, including parser source code and other required information, are generated. Figure 1 shows the generated files. The \u201c.py\u201d contains lexer and parser source code that can parse any Java input file. The -visitor -listener switches in the second command result in generating two separate source files, JavaLabledParserListener.py and JavaLabledParserVistor.py , which provide interfaces to implement the required codes for a specific language application. Our application is source code refactoring which uses the listener mechanism to implement necessary actions transforming the program to the refactored version. The parse tree structure in and listener mechanism are discussed in the next sections. Figure 1. Generated files by ANTLR. It should be noted that to use the generated classes in Figure 1, for developing a specific program, we need to install the appropriate ANTLR runtime library. For creating ANTLR-based programs in Python, the command pip install antlr-python3-runtime can be used. It installed all runtime dependencies required to program using the ANTLR library. ANTLR parse tree The generated parser by ANTLR is responsible for parsing every Java source code file and generating the parse tree or designating the syntax errors in the input file. The parse tree for real-world programs with thousands of lines of code has a non-trivial structure. ANTLR developers have provided some IDE plugins that can visualize the parse tree to better understand the structure of the parse tree generated by ANTLR. We use Pycharm IDE developed by Jetbrains to work with Python code. Figure 2 shows how we can install the ANTLR plugin in PyCharm. The plugin source code is available on the GitHub repo . When the plugin is installed, the ANTLR preview widow is applied at the bottom of the PyCharm IDE. In addition, the IDE can be recognized as \u201c.g4\u201d files and some other options added to the IDE. The main option is the ability to test a grammar rule and visualize the corresponding parse tree to that rule. Figure 2. Installing the ANTLR plugin in the PyCharm IDE. In order to use the ANTLR preview tab, the ANTLR grammar should be opened in the PyCharm IDE. We then select a rule (typically the start rule) of our grammar, right-click on the rule, and select the \u201cTest Rule rule_name \u201d option from the opened menu, shown in Figure 3. We now write our sample input program in the left panel of the ANTLR preview, and the parse tree is shown in the right panel. Figure 3. Test the grammar rule in the ANTLR PyCharm plugin. Figure 4 shows a simple Java class and the corresponding parse tree generated by the ANTLR. The leaves of the parse tree are program tokens, while the intermediate nodes are grammar rules that the evaluating program is derived from them. Also, the root of the tree is the grammar rule, which we selected to start parsing. It means that we can select and test every rule independently. However, a complete Java program can only parse from the start rule of the given grammar, i.e., the compilaionUnit rule. Figure 4. Test the grammar rule in the ANTLR PyCharm plugin. It should be mentioned that the ANTLR Preview window is based on a grammar interpreter, not on the actual generated parser described in the previous section. It means that grammar attributes such as actions and predicates will not be evaluated during live preview because the interpreter is language agnostic. For the same reasons, if the generated parser and/or lexer classes extend a custom implementation of the base parser/lexer classes, the custom code will not be run during the live preview. In addition to the parse tree visualization, the ANTLR plugin provides facilities such as profiling, code generation, etc., described in here (Parr 2022b). For example, the profile tab shows the execution time of each rule in the parser for a given input string. I want to emphasize that visualizing the parse tree with the ANTLR plugin is really helpful when developing code and fixing bugs described in the next section of this tutorial. Traversing the parse tree programmatically ANTLR is not a simple parser generator. It provides a depth-first parse tree visiting and a callback mechanism called listener to implement the required program analysis or transformation passes. The depth-first search is performed by instantiating an object from the ANTLR ParseTreeWalker class and calling the walk method, which takes an instance of ParseTree as an input argument and traverses it. Obviously, if we visit the parse tree with the depth-first search algorithm, all program tokens are visited in the same order that they appeared in the source code file. However, the depth-first search contains additional information about when a node in the tree is visited and when the visiting all nodes in its subtree is finished. Therefore, we can add the required actions when visiting a node to perform a special task. For example, according to Figure 4, for counting the number of classes in a code snippet, we can define a counter variable, initialize it to zero, and increase it whenever the walker visits the \u201cclassDeclartion\u201d node. ANTLR provides two callback functions for each node in the parse tree. One is called by the walker when it is entered into a node, i.e., visit the node, but the children are not visited yet. Another is called when all nodes in the subtree of the visited node have been visited, and the walker is exiting the node. These callback functions are available in the listener class generated by the ANTLR for every rule in a given grammar. In our example for counting the number of classes, we implement all required logic in the body of enterClassDeclartion method of the JavaLabledParserListener class. We called these logic codes grammar\u2019s actions since, indeed, they are bunded to a grammar rule. It is worth noting that we can add these actions codes in the grammar file ( .g4 file) to form an attributed grammar. Embedding actions in grammar increase the efficiency of the analyzing process. However, when we need many complex actions, the listener mechanism provides a better way to implement them. Indeed, ANTLR 4 emphasizes separating the language applications from the language grammar by using the listener mechanism. Listing 1 shows the implementation program for counting the number of classes using the ANTLR listener mechanism. The DesignMetrics class inherits from JavaLabeledParserListener class which is the default listener class generated by ANTLR. We only implement the enterClassDeclartion method, which increases the value of the __dsc counter each time the walker visits a Java class. # module: JavaLabledParserListener.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * if __name__ is not None and \".\" in __name__: from .JavaLabeledParser import JavaLabeledParser else: from JavaLabeledParser import JavaLabeledParser class JavaLabeledParserListener(ParseTreeListener): # \u2026 def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): pass # \u2026 class DesignMetrics(JavaLabeledParserListener): def __init__(self): self.__dsc:int = 0 # Keep design size in classes @property def get_design_size(self): return self.__dsc def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): self.__dsc += 1 Listing 1: Programs that count the number of classes in a Java source code. Wiring the modules To complete our simple analysis task, first, the parse tree for a given input should be constructed. Then, the DesignMetrics class should be instantiated and passed to an object of ParseTreeWalker class. We created a driver module in Python beside the generated code by ANTLR to connect different parts of our program and complete our task. Listing 2 shows the implementation of the main driver for a program that counts the number of classes in Java source codes. # Module: main_driver.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * from JavaLabledLexer import JavaLabledLexer from JavaLeabledParser import JavaLabledParser from JavaLabledParserListener import DesignMetrics def main(args): # Step 1: Load input source into the stream object stream = FileStream(args.file, encoding='utf8') # Step 2: Create an instance of AssignmentStLexer lexer = JavaLabledLexer(stream) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create an instance of the AssignmentStParser parser = JavaLabledParser(token_stream) # Step 5: Create parse tree parse_tree = parser.compilationUnit() # Step 6: Create an instance of DesignMetrics listener class my_listener = DesignMetrics() # Step 7: Create a walker to traverse the parse tree and callback our listener walker = ParseTreeWalker() walker.walk(t=parse_tree, listener=my_listener) # Step 8: Getting the results print(f'DSC={my_listener.get_design_size}') Listing 2: Main driver module for the program in Listing 1 Conclusion and remarks In this tutorial, we described the basic concepts regarding using the ANTLR tool to generate and walk phase three and implement custom program analysis applications with the help of the ANTLR listener mechanism. The most important point is that we used the real-world programming languages grammars to show the parsing and analyzing process. The discussed topics form the underlying concepts of our approach for automated refactoring used in CodART. Check out the ANTLR advanced tutorial to find out how we can use ANTLR for reliable and efficient program transformation. References Parr T ANTLR (ANother Tool for Language Recognition). https://www.antlr.org. Accessed 10 Jan 2022a Parr T IntelliJ Idea Plugin for ANTLR v4. https://github.com/antlr/intellij-plugin-v4. Accessed 10 Jan 2022b Parr T, Fisher K (2011) LL(*): the foundation of the ANTLR parser generator. Proc 32nd ACM SIGPLAN Conf Program Lang Des Implement 425\u2013436. https://doi.org/http://doi.acm.org/10.1145/1993498.1993548","title":"Basic"},{"location":"antlr_tutorials/antlr_basics/#antlr-basic-tutorials","text":"By: Morteza Zakeri Last update: April 30, 2022","title":"ANTLR basic tutorials"},{"location":"antlr_tutorials/antlr_basics/#introduction","text":"The ANTLR tool generates a top-down parser from the grammar rules defined with the ANTLR meta-grammar (Parr and Fisher 2011). The initial version of ANTLR generated the target parser source code in Java. In the current version (version 4), the parser source code can be generated in a wide range of programming languages listed on the ANTLR official website (Parr 2022a). For simplicity, we generate the parser in Python 3, which provides us to run the tool on every platform having Python 3 installed on it. Another reason to use Python is that we can integrate the developed program easily with other libraries available in Python, such as machine learning and optimization libraries. Finally, I found that there is no comprehensive tutorial on using ANTLR with the Python backend. To use ANTLR in other programming languages, specifically Java and C#, refer to the ANTLR slides I created before this tutorial. The ANTLR tool is a small \u201c.jar\u201d file that must be run from the command line to generate the parser codes. The ANTLR tool jar file can be downloaded from here .","title":"Introduction"},{"location":"antlr_tutorials/antlr_basics/#generating-parser","text":"As mentioned, to generate a parser for a programming language, the grammar specification described with ANTLR meta-grammar is required. ANTLR grammar files are named with the \u201c.g4\u201d suffix. We obtain the grammar of Java 8 to build our parser for the Java programming language. The grammar can be downloaded from ANTLR 4 grammar repository on GitHub: https://github.com/antlr/grammars-v4 . Once the ANTLR tool and required grammar files are prepared, we can generate the parser for that with the following command: > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -o . JavaLexer.g4 > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -visitor -listener -o . JavaLabeledParser.g4 The first command generates the lexer from the JavaLexer.g4 description file and the second command generates the parser from the JavaLabeledParser.g4 description file. It is worth noting that the lexer and parser can be written in one file. In such a case, a single command generates all required codes in one step. The grammar files used in the above command are also available in grammars directory of the CodART repository. You may see that I have made some modifications to the Parser rules. In the above commands, the antlr-4.9.3-complete.jar is the ANTLR tool that requires Java to be executed. -Dlanguage denotes the destination language that the ANTLR parser (and lexer) source code is generated in which. In our case, we set it to Python3. After executing the ANTLR parser generation commands, eight files, including parser source code and other required information, are generated. Figure 1 shows the generated files. The \u201c.py\u201d contains lexer and parser source code that can parse any Java input file. The -visitor -listener switches in the second command result in generating two separate source files, JavaLabledParserListener.py and JavaLabledParserVistor.py , which provide interfaces to implement the required codes for a specific language application. Our application is source code refactoring which uses the listener mechanism to implement necessary actions transforming the program to the refactored version. The parse tree structure in and listener mechanism are discussed in the next sections. Figure 1. Generated files by ANTLR. It should be noted that to use the generated classes in Figure 1, for developing a specific program, we need to install the appropriate ANTLR runtime library. For creating ANTLR-based programs in Python, the command pip install antlr-python3-runtime can be used. It installed all runtime dependencies required to program using the ANTLR library.","title":"Generating parser"},{"location":"antlr_tutorials/antlr_basics/#antlr-parse-tree","text":"The generated parser by ANTLR is responsible for parsing every Java source code file and generating the parse tree or designating the syntax errors in the input file. The parse tree for real-world programs with thousands of lines of code has a non-trivial structure. ANTLR developers have provided some IDE plugins that can visualize the parse tree to better understand the structure of the parse tree generated by ANTLR. We use Pycharm IDE developed by Jetbrains to work with Python code. Figure 2 shows how we can install the ANTLR plugin in PyCharm. The plugin source code is available on the GitHub repo . When the plugin is installed, the ANTLR preview widow is applied at the bottom of the PyCharm IDE. In addition, the IDE can be recognized as \u201c.g4\u201d files and some other options added to the IDE. The main option is the ability to test a grammar rule and visualize the corresponding parse tree to that rule. Figure 2. Installing the ANTLR plugin in the PyCharm IDE. In order to use the ANTLR preview tab, the ANTLR grammar should be opened in the PyCharm IDE. We then select a rule (typically the start rule) of our grammar, right-click on the rule, and select the \u201cTest Rule rule_name \u201d option from the opened menu, shown in Figure 3. We now write our sample input program in the left panel of the ANTLR preview, and the parse tree is shown in the right panel. Figure 3. Test the grammar rule in the ANTLR PyCharm plugin. Figure 4 shows a simple Java class and the corresponding parse tree generated by the ANTLR. The leaves of the parse tree are program tokens, while the intermediate nodes are grammar rules that the evaluating program is derived from them. Also, the root of the tree is the grammar rule, which we selected to start parsing. It means that we can select and test every rule independently. However, a complete Java program can only parse from the start rule of the given grammar, i.e., the compilaionUnit rule. Figure 4. Test the grammar rule in the ANTLR PyCharm plugin. It should be mentioned that the ANTLR Preview window is based on a grammar interpreter, not on the actual generated parser described in the previous section. It means that grammar attributes such as actions and predicates will not be evaluated during live preview because the interpreter is language agnostic. For the same reasons, if the generated parser and/or lexer classes extend a custom implementation of the base parser/lexer classes, the custom code will not be run during the live preview. In addition to the parse tree visualization, the ANTLR plugin provides facilities such as profiling, code generation, etc., described in here (Parr 2022b). For example, the profile tab shows the execution time of each rule in the parser for a given input string. I want to emphasize that visualizing the parse tree with the ANTLR plugin is really helpful when developing code and fixing bugs described in the next section of this tutorial.","title":"ANTLR parse tree"},{"location":"antlr_tutorials/antlr_basics/#traversing-the-parse-tree-programmatically","text":"ANTLR is not a simple parser generator. It provides a depth-first parse tree visiting and a callback mechanism called listener to implement the required program analysis or transformation passes. The depth-first search is performed by instantiating an object from the ANTLR ParseTreeWalker class and calling the walk method, which takes an instance of ParseTree as an input argument and traverses it. Obviously, if we visit the parse tree with the depth-first search algorithm, all program tokens are visited in the same order that they appeared in the source code file. However, the depth-first search contains additional information about when a node in the tree is visited and when the visiting all nodes in its subtree is finished. Therefore, we can add the required actions when visiting a node to perform a special task. For example, according to Figure 4, for counting the number of classes in a code snippet, we can define a counter variable, initialize it to zero, and increase it whenever the walker visits the \u201cclassDeclartion\u201d node. ANTLR provides two callback functions for each node in the parse tree. One is called by the walker when it is entered into a node, i.e., visit the node, but the children are not visited yet. Another is called when all nodes in the subtree of the visited node have been visited, and the walker is exiting the node. These callback functions are available in the listener class generated by the ANTLR for every rule in a given grammar. In our example for counting the number of classes, we implement all required logic in the body of enterClassDeclartion method of the JavaLabledParserListener class. We called these logic codes grammar\u2019s actions since, indeed, they are bunded to a grammar rule. It is worth noting that we can add these actions codes in the grammar file ( .g4 file) to form an attributed grammar. Embedding actions in grammar increase the efficiency of the analyzing process. However, when we need many complex actions, the listener mechanism provides a better way to implement them. Indeed, ANTLR 4 emphasizes separating the language applications from the language grammar by using the listener mechanism. Listing 1 shows the implementation program for counting the number of classes using the ANTLR listener mechanism. The DesignMetrics class inherits from JavaLabeledParserListener class which is the default listener class generated by ANTLR. We only implement the enterClassDeclartion method, which increases the value of the __dsc counter each time the walker visits a Java class. # module: JavaLabledParserListener.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * if __name__ is not None and \".\" in __name__: from .JavaLabeledParser import JavaLabeledParser else: from JavaLabeledParser import JavaLabeledParser class JavaLabeledParserListener(ParseTreeListener): # \u2026 def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): pass # \u2026 class DesignMetrics(JavaLabeledParserListener): def __init__(self): self.__dsc:int = 0 # Keep design size in classes @property def get_design_size(self): return self.__dsc def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): self.__dsc += 1 Listing 1: Programs that count the number of classes in a Java source code.","title":"Traversing the parse tree programmatically"},{"location":"antlr_tutorials/antlr_basics/#wiring-the-modules","text":"To complete our simple analysis task, first, the parse tree for a given input should be constructed. Then, the DesignMetrics class should be instantiated and passed to an object of ParseTreeWalker class. We created a driver module in Python beside the generated code by ANTLR to connect different parts of our program and complete our task. Listing 2 shows the implementation of the main driver for a program that counts the number of classes in Java source codes. # Module: main_driver.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * from JavaLabledLexer import JavaLabledLexer from JavaLeabledParser import JavaLabledParser from JavaLabledParserListener import DesignMetrics def main(args): # Step 1: Load input source into the stream object stream = FileStream(args.file, encoding='utf8') # Step 2: Create an instance of AssignmentStLexer lexer = JavaLabledLexer(stream) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create an instance of the AssignmentStParser parser = JavaLabledParser(token_stream) # Step 5: Create parse tree parse_tree = parser.compilationUnit() # Step 6: Create an instance of DesignMetrics listener class my_listener = DesignMetrics() # Step 7: Create a walker to traverse the parse tree and callback our listener walker = ParseTreeWalker() walker.walk(t=parse_tree, listener=my_listener) # Step 8: Getting the results print(f'DSC={my_listener.get_design_size}') Listing 2: Main driver module for the program in Listing 1","title":"Wiring the modules"},{"location":"antlr_tutorials/antlr_basics/#conclusion-and-remarks","text":"In this tutorial, we described the basic concepts regarding using the ANTLR tool to generate and walk phase three and implement custom program analysis applications with the help of the ANTLR listener mechanism. The most important point is that we used the real-world programming languages grammars to show the parsing and analyzing process. The discussed topics form the underlying concepts of our approach for automated refactoring used in CodART. Check out the ANTLR advanced tutorial to find out how we can use ANTLR for reliable and efficient program transformation.","title":"Conclusion and remarks"},{"location":"antlr_tutorials/antlr_basics/#references","text":"Parr T ANTLR (ANother Tool for Language Recognition). https://www.antlr.org. Accessed 10 Jan 2022a Parr T IntelliJ Idea Plugin for ANTLR v4. https://github.com/antlr/intellij-plugin-v4. Accessed 10 Jan 2022b Parr T, Fisher K (2011) LL(*): the foundation of the ANTLR parser generator. Proc 32nd ACM SIGPLAN Conf Program Lang Des Implement 425\u2013436. https://doi.org/http://doi.acm.org/10.1145/1993498.1993548","title":"References"},{"location":"antlr_tutorials/antlr_slides/","text":"ANTLR basic tutorials (slides) By: Morteza Zakeri Last update: May 1, 2022 Introduction to ANTLR: Part I Antlr part1 introduction from Morteza Zakeri Introduction to ANTLR: Part II Antlr part2 getting_started_in_java from Morteza Zakeri Introduction to ANTLR: Part III Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"Slides"},{"location":"antlr_tutorials/antlr_slides/#antlr-basic-tutorials-slides","text":"By: Morteza Zakeri Last update: May 1, 2022","title":"ANTLR basic tutorials (slides)"},{"location":"antlr_tutorials/antlr_slides/#introduction-to-antlr-part-i","text":"Antlr part1 introduction from Morteza Zakeri","title":"Introduction to ANTLR: Part I"},{"location":"antlr_tutorials/antlr_slides/#introduction-to-antlr-part-ii","text":"Antlr part2 getting_started_in_java from Morteza Zakeri","title":"Introduction to ANTLR: Part II"},{"location":"antlr_tutorials/antlr_slides/#introduction-to-antlr-part-iii","text":"Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"Introduction to ANTLR: Part III"},{"location":"assignments/programming_assignment/","text":"Programming assignments Current semester Archive Semester 971 Semester 962 Semester 961","title":"Programming assignments"},{"location":"assignments/programming_assignment/#programming-assignments","text":"","title":"Programming assignments"},{"location":"assignments/programming_assignment/#current-semester","text":"","title":"Current semester"},{"location":"assignments/programming_assignment/#archive","text":"","title":"Archive"},{"location":"assignments/programming_assignment/#semester-971","text":"","title":"Semester 971"},{"location":"assignments/programming_assignment/#semester-962","text":"","title":"Semester 962"},{"location":"assignments/programming_assignment/#semester-961","text":"","title":"Semester 961"},{"location":"assignments/writing_assignments/","text":"Writing assignments Current semester Archive Semester 971 HW1 HW2 HW3 (Dr. Parsa Questions) Semester 962 HW1 HW2 HW3 HW4","title":"Writing assignments"},{"location":"assignments/writing_assignments/#writing-assignments","text":"","title":"Writing assignments"},{"location":"assignments/writing_assignments/#current-semester","text":"","title":"Current semester"},{"location":"assignments/writing_assignments/#archive","text":"","title":"Archive"},{"location":"assignments/writing_assignments/#semester-971","text":"HW1 HW2 HW3 (Dr. Parsa Questions)","title":"Semester 971"},{"location":"assignments/writing_assignments/#semester-962","text":"HW1 HW2 HW3 HW4","title":"Semester 962"},{"location":"language_applications/assignment_statement1main/","text":"Assignment statement grammar (version 1) Main script for grammar AssignmentStatement1 (version 1) author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201029 Required Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v2.0.0 A lexer and parser for simple grammar without any attribute or listener Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ main ( args ) Create lexer and parser Parameters: Name Type Description Default args str required return None required Source code in language_apps\\assignment_statement_v1\\assignment_statement1main.py def main ( args ): \"\"\" Create lexer and parser Args: args (str): return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement1Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement1Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () # return lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"Assignment statement 1"},{"location":"language_applications/assignment_statement1main/#assignment-statement-grammar-version-1","text":"Main script for grammar AssignmentStatement1 (version 1)","title":"Assignment statement grammar (version 1)"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--date","text":"20201029","title":"date"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--required","text":"Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"Required"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--v200","text":"A lexer and parser for simple grammar without any attribute or listener","title":"v2.0.0"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main.main","text":"Create lexer and parser Parameters: Name Type Description Default args str required return None required Source code in language_apps\\assignment_statement_v1\\assignment_statement1main.py def main ( args ): \"\"\" Create lexer and parser Args: args (str): return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement1Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement1Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () # return lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"main()"},{"location":"language_applications/assignment_statement2main/","text":"Assignment statement grammar (version 2) Tree address code generation pass ANTLR 4.x listener and visitor implementation for intermediate code generation (Three addresses code) @author: Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) @date: 20201017 Compiler generator: ANTRL4.x Target language(s): Python3.x, -Changelog: -- v2.1.0 --- Add support for AST intermediate representation using module ast_pass --- Change compiler_pass module to three_address_code_pass -- v2.0.0 --- Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules. Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ ThreeAddressCodeGenerator2Listener Type checking and generating three address language_apps (optimizing number of temporary variables) ThreeAddressCodeGenerator2Visitor Type checking and generating three address language_apps (optimizing number of temporary variables) Utilizing ANTLR 4.x Visitor mechanism ThreeAddressCodeGeneratorListener Type checking and generating three address language_apps (not optimized) ThreeAddressCodeGeneratorVisitor Type checking and generating three address language_apps (not optimized regarding to the number of temporary variables) Utilizing ANTLR 4.x Visitor mechanism Abstract syntax tree (AST) generation pass ANTLR 4.x listener and visitor implementation for intermediate code generation (abstract syntax trees) @author: Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) @date: 20201117 Compiler generator: ANTRL4.x Target language(s): Python3.x, -Changelog: -- v2.1.0 --- Add support for AST visualization with dummy nodes --- Add support for AST intermediate representation using module ast_pass --- Change compiler_pass module to three_address_code_pass -- v2.0.0 --- Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules. Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ ASTListener Main driver Main script for grammar AssignmentStatement2 (version 2) Contains attributes for holding rule type and rule intermediate representations (AST and Three-addresses codes) author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201029 Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Install pygraphviz To draw AST as a binary tree you need to install the pygraphviz 1- download and install graphviz (for Windows/ Linux) 2- add graphviz to system path 3- install pygraphviz using the following command python -m pip install --global-option=build_ext --global-option=\"-IC:\\Program Files\\Graphviz\\include\" --global-option=\"-LC:\\Program Files\\Graphviz\\lib\" pygraphviz Changelog v2.1.1 Add visualization with Graphviz. v2.1.0 Add support for AST intermediate representation using module ast_pass Change compiler_pass module to three_address_code_pass v2.0.0 Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules. Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ draw ( g = None ) Draw abstract syntax tree Parameters: Name Type Description Default g DiGraph None Returns: Type Description None Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def draw ( g : nx . DiGraph = None ): \"\"\" Draw abstract syntax tree Args: g (nx.DiGraph) : Returns: None \"\"\" pos = graphviz_layout ( G = g , prog = 'dot' , # prog='circo', ) # pos = hierarchy_pos(G=g,) # pos = nx.kamada_kawai_layout(G=g) # pos = nx.bipartite_layout(G=g, nodes=g.nodes) # pos = nx.spectral_layout(G=g) # pos = nx.spiral_layout(G=g) # pos = nx.spiral_layout(G=g) colors = [ g [ u ][ v ][ 'color' ] for u , v in g . edges ] nx . draw ( g , with_labels = False , node_size = 500 , node_color = 'black' , edge_color = colors , pos = pos , ) edge_labels = nx . get_edge_attributes ( g , 'edge_type' ) # print('#', edge_labels) nx . draw_networkx_edge_labels ( g , pos , edge_labels = edge_labels , ) node_labels = {} for node in g . nodes (): # set the node name as the key and the label as its value node_labels [ node ] = node . value nx . draw_networkx_labels ( g , pos , node_labels , font_size = 12 , font_color = 'w' ) plt . savefig ( '../../docs/figs/ast4.png' ) plt . show () draw_graphviz ( g = None ) Visualize abstract syntax tree with Graphviz Arges: g (nx.DiGraph): The abstract syntax tree to be converted to the dot file Returns: Type Description None References: [1] https://graphviz.org/Gallery/directed/psg.html Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def draw_graphviz ( g : nx . DiGraph = None ): \"\"\" Visualize abstract syntax tree with Graphviz Arges: g (nx.DiGraph): The abstract syntax tree to be converted to the dot file Returns: None References: [1] https://graphviz.org/Gallery/directed/psg.html \"\"\" pydot_graph = nx . drawing . nx_pydot . to_pydot ( g ) # nx.drawing.nx_pydot.write_dot(func_graph, self.cfg_path + str(self.domain_name) + '.dot') pydot_graph2 = pydot . Dot ( \"\" , graph_type = \"digraph\" ) nid = 0 for u , v in g . edges : if u . value == u ' \\u2593 ' : # u.value = 'NULL' node_u = pydot . Node ( name = f 'node_id_ { nid } ' , label = u . value , shape = 'box' ) nid += 1 else : node_u = pydot . Node ( name = u . value , label = u . value , shape = 'box' ) if v . value == u ' \\u2593 ' : # v.value = 'NULL' node_v = pydot . Node ( name = f 'node_id_ { nid } ' , label = v . value , shape = 'box' ) nid += 1 else : node_v = pydot . Node ( name = v . value , label = v . value , shape = 'box' ) print ( u . value , v . value ) # edge_obj_dict = dict() # edge_obj_dict.update({'color': g[u][v]['color']}) # edge_obj_dict.update({'label': g[u][v]['edge_type']}) edge_ = pydot . Edge ( src = node_u , dst = node_v , color = g [ u ][ v ][ 'color' ], label = g [ u ][ v ][ 'edge_type' ]) pydot_graph2 . add_node ( node_u ) pydot_graph2 . add_node ( node_v ) pydot_graph2 . add_edge ( edge_ ) pydot_graph2 . write ( '../../docs/figs/ast2gv.dot' , encoding = 'utf-8' , ) # pydot_graph2.write_png('../../docs/figs/ast2.png') result = subprocess . run ( [ 'dot' , '-Tpng' , '../../docs/figs/ast2gv.dot' , '-o' , '../../docs/figs/ast2gv.png' ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) print ( result . returncode ) error_ = result . stderr . decode ( 'utf-8' ) print ( error_ ) hierarchy_pos ( G , root = None , width = 1.0 , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 ) From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Parameters: Name Type Description Default G nx.Graph the graph (must be a tree) required root nx.Node the root node of current branch None width float horizontal space allocated for this branch - avoids overlap with other branches 1.0 vert_gap float gap between levels of hierarchy 0.2 vert_loc float vertical location of root 0 xcenter float horizontal location of root 0.5 Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def hierarchy_pos ( G , root = None , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 ): \"\"\" From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Args: G (nx.Graph): the graph (must be a tree) root (nx.Node): the root node of current branch - if the tree is directed and this is not given, the root will be found and used - if the tree is directed and this is given, then the positions will be just for the descendants of this node. - if the tree is undirected and not given,then a random choice will be used. width (float): horizontal space allocated for this branch - avoids overlap with other branches vert_gap (float): gap between levels of hierarchy vert_loc (float): vertical location of root xcenter (float): horizontal location of root \"\"\" if not nx . is_tree ( G ): raise TypeError ( 'cannot use hierarchy_pos on a graph that is not a tree' ) if root is None : if isinstance ( G , nx . DiGraph ): root = next ( iter ( nx . topological_sort ( G ))) # allows back compatibility with nx version 1.11 else : root = random . choice ( list ( G . nodes )) def _hierarchy_pos ( G , root , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 , pos = None , parent = None ): \"\"\" see hierarchy_pos docstring for most arguments pos: a dict saying where all nodes go if they have been assigned parent: parent of this branch. - only affects it if non-directed \"\"\" if pos is None : pos = { root : ( xcenter , vert_loc )} else : pos [ root ] = ( xcenter , vert_loc ) children = list ( G . neighbors ( root )) if not isinstance ( G , nx . DiGraph ) and parent is not None : children . remove ( parent ) if len ( children ) != 0 : dx = width / len ( children ) nextx = xcenter - width / 2 - dx / 2 for child in children : nextx += dx pos = _hierarchy_pos ( G , child , width = dx , vert_gap = vert_gap , vert_loc = vert_loc - vert_gap , xcenter = nextx , pos = pos , parent = root ) return pos return _hierarchy_pos ( G , root , width , vert_gap , vert_loc , xcenter ) main ( args ) Create lexer and parser and execute AST listener Parameters: Name Type Description Default args Arg required Returns: Type Description None Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def main ( args ): \"\"\" Create lexer and parser and execute AST listener Args: args (Arg): Returns: None \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) print ( 'Input language_apps: \\n {0} ' . format ( stream )) print ( 'Result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement2Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement2Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener # code_generator_listener = ThreeAddressCodeGeneratorListener() # code_generator_listener = ThreeAddressCodeGenerator2Listener() ast_generator = ASTListener () # Step 7(a): Walk parse tree with a customized listener (Automatically) walker = ParseTreeWalker () # walker.walk(t=parse_tree, listener=code_generator_listener) # or walker . walk ( t = parse_tree , listener = ast_generator ) # print('\\nG=', ast_generator.g.edges) # draw(g=ast_generator.g) draw_graphviz ( g = ast_generator . g ) # Step 7(b): Walk parse tree with a customize visitor (Manually) # code_generator_vistor = ThreeAddressCodeGeneratorVisitor() # code_generator_vistor = ThreeAddressCodeGenerator2Visitor() # code_generator_vistor.visitStart(ctx=parse_tree.getRuleContext())","title":"Assignment statement 2"},{"location":"language_applications/assignment_statement2main/#assignment-statement-grammar-version-2","text":"","title":"Assignment statement grammar (version 2)"},{"location":"language_applications/assignment_statement2main/#tree-address-code-generation-pass","text":"ANTLR 4.x listener and visitor implementation for intermediate code generation (Three addresses code) @author: Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) @date: 20201017 Compiler generator: ANTRL4.x Target language(s): Python3.x, -Changelog: -- v2.1.0 --- Add support for AST intermediate representation using module ast_pass --- Change compiler_pass module to three_address_code_pass -- v2.0.0 --- Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules. Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Tree address code generation pass"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.three_address_code_pass.ThreeAddressCodeGenerator2Listener","text":"Type checking and generating three address language_apps (optimizing number of temporary variables)","title":"ThreeAddressCodeGenerator2Listener"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.three_address_code_pass.ThreeAddressCodeGenerator2Visitor","text":"Type checking and generating three address language_apps (optimizing number of temporary variables) Utilizing ANTLR 4.x Visitor mechanism","title":"ThreeAddressCodeGenerator2Visitor"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.three_address_code_pass.ThreeAddressCodeGeneratorListener","text":"Type checking and generating three address language_apps (not optimized)","title":"ThreeAddressCodeGeneratorListener"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.three_address_code_pass.ThreeAddressCodeGeneratorVisitor","text":"Type checking and generating three address language_apps (not optimized regarding to the number of temporary variables) Utilizing ANTLR 4.x Visitor mechanism","title":"ThreeAddressCodeGeneratorVisitor"},{"location":"language_applications/assignment_statement2main/#abstract-syntax-tree-ast-generation-pass","text":"ANTLR 4.x listener and visitor implementation for intermediate code generation (abstract syntax trees) @author: Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) @date: 20201117 Compiler generator: ANTRL4.x Target language(s): Python3.x, -Changelog: -- v2.1.0 --- Add support for AST visualization with dummy nodes --- Add support for AST intermediate representation using module ast_pass --- Change compiler_pass module to three_address_code_pass -- v2.0.0 --- Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules. Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Abstract syntax tree (AST) generation pass"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.abstract_syntax_tree_pass.ASTListener","text":"","title":"ASTListener"},{"location":"language_applications/assignment_statement2main/#main-driver","text":"Main script for grammar AssignmentStatement2 (version 2) Contains attributes for holding rule type and rule intermediate representations (AST and Three-addresses codes)","title":"Main driver"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--date","text":"20201029 Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"date"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--install-pygraphviz","text":"To draw AST as a binary tree you need to install the pygraphviz 1- download and install graphviz (for Windows/ Linux) 2- add graphviz to system path 3- install pygraphviz using the following command python -m pip install --global-option=build_ext --global-option=\"-IC:\\Program Files\\Graphviz\\include\" --global-option=\"-LC:\\Program Files\\Graphviz\\lib\" pygraphviz","title":"Install pygraphviz"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--v211","text":"Add visualization with Graphviz.","title":"v2.1.1"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--v210","text":"Add support for AST intermediate representation using module ast_pass Change compiler_pass module to three_address_code_pass","title":"v2.1.0"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--v200","text":"Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules.","title":"v2.0.0"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.draw","text":"Draw abstract syntax tree Parameters: Name Type Description Default g DiGraph None Returns: Type Description None Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def draw ( g : nx . DiGraph = None ): \"\"\" Draw abstract syntax tree Args: g (nx.DiGraph) : Returns: None \"\"\" pos = graphviz_layout ( G = g , prog = 'dot' , # prog='circo', ) # pos = hierarchy_pos(G=g,) # pos = nx.kamada_kawai_layout(G=g) # pos = nx.bipartite_layout(G=g, nodes=g.nodes) # pos = nx.spectral_layout(G=g) # pos = nx.spiral_layout(G=g) # pos = nx.spiral_layout(G=g) colors = [ g [ u ][ v ][ 'color' ] for u , v in g . edges ] nx . draw ( g , with_labels = False , node_size = 500 , node_color = 'black' , edge_color = colors , pos = pos , ) edge_labels = nx . get_edge_attributes ( g , 'edge_type' ) # print('#', edge_labels) nx . draw_networkx_edge_labels ( g , pos , edge_labels = edge_labels , ) node_labels = {} for node in g . nodes (): # set the node name as the key and the label as its value node_labels [ node ] = node . value nx . draw_networkx_labels ( g , pos , node_labels , font_size = 12 , font_color = 'w' ) plt . savefig ( '../../docs/figs/ast4.png' ) plt . show ()","title":"draw()"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.draw_graphviz","text":"Visualize abstract syntax tree with Graphviz Arges: g (nx.DiGraph): The abstract syntax tree to be converted to the dot file Returns: Type Description None References: [1] https://graphviz.org/Gallery/directed/psg.html Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def draw_graphviz ( g : nx . DiGraph = None ): \"\"\" Visualize abstract syntax tree with Graphviz Arges: g (nx.DiGraph): The abstract syntax tree to be converted to the dot file Returns: None References: [1] https://graphviz.org/Gallery/directed/psg.html \"\"\" pydot_graph = nx . drawing . nx_pydot . to_pydot ( g ) # nx.drawing.nx_pydot.write_dot(func_graph, self.cfg_path + str(self.domain_name) + '.dot') pydot_graph2 = pydot . Dot ( \"\" , graph_type = \"digraph\" ) nid = 0 for u , v in g . edges : if u . value == u ' \\u2593 ' : # u.value = 'NULL' node_u = pydot . Node ( name = f 'node_id_ { nid } ' , label = u . value , shape = 'box' ) nid += 1 else : node_u = pydot . Node ( name = u . value , label = u . value , shape = 'box' ) if v . value == u ' \\u2593 ' : # v.value = 'NULL' node_v = pydot . Node ( name = f 'node_id_ { nid } ' , label = v . value , shape = 'box' ) nid += 1 else : node_v = pydot . Node ( name = v . value , label = v . value , shape = 'box' ) print ( u . value , v . value ) # edge_obj_dict = dict() # edge_obj_dict.update({'color': g[u][v]['color']}) # edge_obj_dict.update({'label': g[u][v]['edge_type']}) edge_ = pydot . Edge ( src = node_u , dst = node_v , color = g [ u ][ v ][ 'color' ], label = g [ u ][ v ][ 'edge_type' ]) pydot_graph2 . add_node ( node_u ) pydot_graph2 . add_node ( node_v ) pydot_graph2 . add_edge ( edge_ ) pydot_graph2 . write ( '../../docs/figs/ast2gv.dot' , encoding = 'utf-8' , ) # pydot_graph2.write_png('../../docs/figs/ast2.png') result = subprocess . run ( [ 'dot' , '-Tpng' , '../../docs/figs/ast2gv.dot' , '-o' , '../../docs/figs/ast2gv.png' ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) print ( result . returncode ) error_ = result . stderr . decode ( 'utf-8' ) print ( error_ )","title":"draw_graphviz()"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.hierarchy_pos","text":"From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Parameters: Name Type Description Default G nx.Graph the graph (must be a tree) required root nx.Node the root node of current branch None width float horizontal space allocated for this branch - avoids overlap with other branches 1.0 vert_gap float gap between levels of hierarchy 0.2 vert_loc float vertical location of root 0 xcenter float horizontal location of root 0.5 Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def hierarchy_pos ( G , root = None , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 ): \"\"\" From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Args: G (nx.Graph): the graph (must be a tree) root (nx.Node): the root node of current branch - if the tree is directed and this is not given, the root will be found and used - if the tree is directed and this is given, then the positions will be just for the descendants of this node. - if the tree is undirected and not given,then a random choice will be used. width (float): horizontal space allocated for this branch - avoids overlap with other branches vert_gap (float): gap between levels of hierarchy vert_loc (float): vertical location of root xcenter (float): horizontal location of root \"\"\" if not nx . is_tree ( G ): raise TypeError ( 'cannot use hierarchy_pos on a graph that is not a tree' ) if root is None : if isinstance ( G , nx . DiGraph ): root = next ( iter ( nx . topological_sort ( G ))) # allows back compatibility with nx version 1.11 else : root = random . choice ( list ( G . nodes )) def _hierarchy_pos ( G , root , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 , pos = None , parent = None ): \"\"\" see hierarchy_pos docstring for most arguments pos: a dict saying where all nodes go if they have been assigned parent: parent of this branch. - only affects it if non-directed \"\"\" if pos is None : pos = { root : ( xcenter , vert_loc )} else : pos [ root ] = ( xcenter , vert_loc ) children = list ( G . neighbors ( root )) if not isinstance ( G , nx . DiGraph ) and parent is not None : children . remove ( parent ) if len ( children ) != 0 : dx = width / len ( children ) nextx = xcenter - width / 2 - dx / 2 for child in children : nextx += dx pos = _hierarchy_pos ( G , child , width = dx , vert_gap = vert_gap , vert_loc = vert_loc - vert_gap , xcenter = nextx , pos = pos , parent = root ) return pos return _hierarchy_pos ( G , root , width , vert_gap , vert_loc , xcenter )","title":"hierarchy_pos()"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.main","text":"Create lexer and parser and execute AST listener Parameters: Name Type Description Default args Arg required Returns: Type Description None Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def main ( args ): \"\"\" Create lexer and parser and execute AST listener Args: args (Arg): Returns: None \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) print ( 'Input language_apps: \\n {0} ' . format ( stream )) print ( 'Result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement2Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement2Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener # code_generator_listener = ThreeAddressCodeGeneratorListener() # code_generator_listener = ThreeAddressCodeGenerator2Listener() ast_generator = ASTListener () # Step 7(a): Walk parse tree with a customized listener (Automatically) walker = ParseTreeWalker () # walker.walk(t=parse_tree, listener=code_generator_listener) # or walker . walk ( t = parse_tree , listener = ast_generator ) # print('\\nG=', ast_generator.g.edges) # draw(g=ast_generator.g) draw_graphviz ( g = ast_generator . g ) # Step 7(b): Walk parse tree with a customize visitor (Manually) # code_generator_vistor = ThreeAddressCodeGeneratorVisitor() # code_generator_vistor = ThreeAddressCodeGenerator2Visitor() # code_generator_vistor.visitStart(ctx=parse_tree.getRuleContext())","title":"main()"},{"location":"language_applications/assignment_statement3main/","text":"Assignment statement grammar (version 3) Main script for grammar AssignmentStatement3 (version 3) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes) author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201028 Required Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v3.0 Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes) Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ main ( args ) Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v3\\assignment_statement3main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement3Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement3Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"Assignment statement 3"},{"location":"language_applications/assignment_statement3main/#assignment-statement-grammar-version-3","text":"Main script for grammar AssignmentStatement3 (version 3) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes)","title":"Assignment statement grammar (version 3)"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--date","text":"20201028","title":"date"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--required","text":"Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"Required"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--v30","text":"Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes)","title":"v3.0"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main.main","text":"Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v3\\assignment_statement3main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement3Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement3Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"main()"},{"location":"language_applications/assignment_statement4main/","text":"Assignment statement grammar (version 4) Main script for grammar AssignmentStatement4 (version 4) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes) Also, generates intermediate representation (three addresses codes) with minimum number of 'temp' variables author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201029 Required Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v4.0 Generate intermediate representation (three addresses codes) with minimum number of 'temp' variables v3.0 Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes) Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ main ( args ) Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v4\\assignment_statement4main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement4Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement4Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"Assignment statement 4"},{"location":"language_applications/assignment_statement4main/#assignment-statement-grammar-version-4","text":"Main script for grammar AssignmentStatement4 (version 4) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes) Also, generates intermediate representation (three addresses codes) with minimum number of 'temp' variables","title":"Assignment statement grammar (version 4)"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--date","text":"20201029","title":"date"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--required","text":"Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"Required"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--v40","text":"Generate intermediate representation (three addresses codes) with minimum number of 'temp' variables","title":"v4.0"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--v30","text":"Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes)","title":"v3.0"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main.main","text":"Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v4\\assignment_statement4main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement4Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement4Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"main()"},{"location":"language_applications/main/","text":"Main There are four language application in this repository assignment_statement_v1 assignment_statement_v2 assignment_statement_v3 assignment_statement_v4 The main module of IUST Compiler project. This module do not contains any code. Please refer to language_apps package to find classroom code snippets. Main Welcome to Compiler course This file contains the main script for all code snippets print_welcome ( name ) classmethod Print welcome message :param name: :return: Source code in iust_compilers_teaching\\main.py @classmethod def print_welcome ( cls , name ) -> None : \"\"\" Print welcome message :param name: :return: \"\"\" method_name = 'getSdfsdfsdtudentNsdfdsfumber' identifier_parts = list () # First: split based-on CamelCase matches = re . finditer ( '.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)' , method_name ) camel_cases = [ m . group ( 0 ) for m in matches ] # Second: split based-on underscore character '_' for case in camel_cases : case = case . lower () case = case . split ( '_' ) identifier_parts . extend ( case ) print ( f 'Method name tokens { camel_cases } .' )","title":"Main"},{"location":"language_applications/main/#main_1","text":"There are four language application in this repository assignment_statement_v1 assignment_statement_v2 assignment_statement_v3 assignment_statement_v4 The main module of IUST Compiler project. This module do not contains any code. Please refer to language_apps package to find classroom code snippets.","title":"Main"},{"location":"language_applications/main/#main.Main","text":"Welcome to Compiler course This file contains the main script for all code snippets","title":"Main"},{"location":"language_applications/main/#main.Main.print_welcome","text":"Print welcome message :param name: :return: Source code in iust_compilers_teaching\\main.py @classmethod def print_welcome ( cls , name ) -> None : \"\"\" Print welcome message :param name: :return: \"\"\" method_name = 'getSdfsdfsdtudentNsdfdsfumber' identifier_parts = list () # First: split based-on CamelCase matches = re . finditer ( '.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)' , method_name ) camel_cases = [ m . group ( 0 ) for m in matches ] # Second: split based-on underscore character '_' for case in camel_cases : case = case . lower () case = case . split ( '_' ) identifier_parts . extend ( case ) print ( f 'Method name tokens { camel_cases } .' )","title":"print_welcome()"},{"location":"lectures/lexical_analysis/","text":"Lexical analysis To be announced.","title":"Lexical analysis"},{"location":"lectures/lexical_analysis/#lexical-analysis","text":"To be announced.","title":"Lexical analysis"},{"location":"projects/core_clean_code_development/","text":"Core clean code development The input to our software tool, cleanCode , is a c# class. cleanCode analyzes the source code and determines how clean the code is. The output is a list of the line numbers of the given class, in which the clean code principles proposed by Robert Martin, in his book, Clean Code, are violated. The current version of cleanCode, checks 14 principles and we are going to add more principles in our next version. Click to visit clean code project .","title":"Clean code"},{"location":"projects/core_clean_code_development/#core-clean-code-development","text":"The input to our software tool, cleanCode , is a c# class. cleanCode analyzes the source code and determines how clean the code is. The output is a list of the line numbers of the given class, in which the clean code principles proposed by Robert Martin, in his book, Clean Code, are violated. The current version of cleanCode, checks 14 principles and we are going to add more principles in our next version. Click to visit clean code project .","title":"Core clean code development"},{"location":"projects/core_code_smell_development/","text":"Core code smell development The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process. Grading policy for BSc students Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) Grading policy for MSc students Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Code smell detection"},{"location":"projects/core_code_smell_development/#core-code-smell-development","text":"The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process.","title":"Core code smell development"},{"location":"projects/core_code_smell_development/#grading-policy-for-bsc-students","text":"Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"projects/core_code_smell_development/#grading-policy-for-msc-students","text":"Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Grading policy for MSc students"},{"location":"projects/core_refactoring_to_design_patterns_development/","text":"Core refactoring to design patterns development To be announced.","title":"Refactoring to patterns"},{"location":"projects/core_refactoring_to_design_patterns_development/#core-refactoring-to-design-patterns-development","text":"To be announced.","title":"Core refactoring to design patterns development"},{"location":"projects/core_refactorings_development/","text":"Core refactoring development The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files. Grading policy for BSc students Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus) Grading policy for MSc students Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Source code refactoring"},{"location":"projects/core_refactorings_development/#core-refactoring-development","text":"The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files.","title":"Core refactoring development"},{"location":"projects/core_refactorings_development/#grading-policy-for-bsc-students","text":"Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"projects/core_refactorings_development/#grading-policy-for-msc-students","text":"Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Grading policy for MSc students"},{"location":"projects/core_source_code_instrumentation_development/","text":"Core source code instrumentation development To be announced.","title":"Source code instrumentation"},{"location":"projects/core_source_code_instrumentation_development/#core-source-code-instrumentation-development","text":"To be announced.","title":"Core source code instrumentation development"}]}